[
  {
    "objectID": "day-21.html",
    "href": "day-21.html",
    "title": "Daily Assignment 21",
    "section": "",
    "text": "library(dplyr)             \n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(dataRetrieval)\nlibrary(tsibble)             \n\nRegistered S3 method overwritten by 'tsibble':\n  method               from \n  as_tibble.grouped_df dplyr\n\n\n\nAttaching package: 'tsibble'\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, union\n\n# Example: Cache la Poudre River at Mouth (USGS site 06752260)\npoudre_flow &lt;- readNWISdv(siteNumber = \"06752260\",    # Download data from USGS for site 06752260\n                          parameterCd = \"00060\",      # Parameter code 00060 = discharge in cfs)\n                          startDate = \"2013-01-01\",   # Set the start date\n                          endDate = \"2023-12-31\") |&gt;  # Set the end date\n  renameNWISColumns() |&gt;                              # Rename columns to standard names (e.g., \"Flow\", \"Date\")\n  mutate(Date = yearmonth(Date)) |&gt;                   # Convert daily Date values into a year-month format (e.g., \"2023 Jan\")\n  group_by(Date) |&gt;                                   # Group the data by the new monthly Date\n  summarise(Flow = mean(Flow))                       # Calculate the average daily flow for each month\n\nGET:https://waterservices.usgs.gov/nwis/dv/?site=06752260&format=waterml%2C1.1&ParameterCd=00060&StatCd=00003&startDT=2013-01-01&endDT=2023-12-31"
  },
  {
    "objectID": "day-21.html#convert-to-tsibble",
    "href": "day-21.html#convert-to-tsibble",
    "title": "Daily Assignment 21",
    "section": "Convert to tsibble:",
    "text": "Convert to tsibble:\n\nlibrary(tsibble)\n\n# Convert the data frame to a tsibble\npoudre_flow_tsibble &lt;- poudre_flow %&gt;%\n  as_tsibble(index = Date)"
  },
  {
    "objectID": "day-21.html#plotting-the-time-series",
    "href": "day-21.html#plotting-the-time-series",
    "title": "Daily Assignment 21",
    "section": "Plotting the time series:",
    "text": "Plotting the time series:\n\nlibrary(ggplot2)\n\n# Static plot\nggplot(poudre_flow_tsibble, aes(x = Date, y = Flow)) +\n  geom_line() +\n  labs(title = \"Monthly Average Flow: Cache la Poudre River\",\n       x = \"Date\", y = \"Flow (cfs)\") +\n  theme_minimal()\n\n\n\n\n\n\n\nlibrary(plotly)\n\n\nAttaching package: 'plotly'\n\n\nThe following object is masked from 'package:ggplot2':\n\n    last_plot\n\n\nThe following object is masked from 'package:stats':\n\n    filter\n\n\nThe following object is masked from 'package:graphics':\n\n    layout\n\n# Animated plot\np &lt;- ggplot(poudre_flow_tsibble, aes(x = Date, y = Flow)) +\n  geom_line() +\n  labs(title = \"Monthly Average Flow: Cache la Poudre River\",\n       x = \"Date\", y = \"Flow (cfs)\") +\n  theme_minimal()\n\nggplotly(p)  # This creates an interactive, animated plot in plotly"
  },
  {
    "objectID": "day-21.html#subseries-plot",
    "href": "day-21.html#subseries-plot",
    "title": "Daily Assignment 21",
    "section": "Subseries plot:",
    "text": "Subseries plot:\n\nlibrary(feasts)\n\nLoading required package: fabletools\n\n# Subseries plot\npoudre_flow_tsibble %&gt;%\n  gg_subseries(Flow) +\n  labs(title = \"Subseries Plot: Cache la Poudre River Flow\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(size = 2))\n\n\n\n\n\n\n\n\n\nDescribe what you see in the plot. How are “seasons” defined in this plot? What do you think the “subseries” represent?\n\nThe plot shows obvious seasonal patterns in streamflow, with the peak flows occuring in May and June. In this graph, seasons are defined as calender months and each panel represents one month across the years of 2013 - 2024. The “subseries” represents the flow values for a specific month over multiple years. This allows for us to observe how streamflow changes from year to year within each month."
  },
  {
    "objectID": "day-09.html",
    "href": "day-09.html",
    "title": "The data does need cleaning.",
    "section": "",
    "text": "library(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(visdat)\nlibrary(tidyr)\nlibrary(ggplot2)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats   1.0.0     ✔ readr     2.1.5\n✔ lubridate 1.9.4     ✔ stringr   1.5.1\n✔ purrr     1.0.4     ✔ tibble    3.2.1\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n?airquality\nvis_dat(airquality)\n\n\n\n\n\n\n\n\n\nThe data does need cleaning.\n\ncleaned_airdata &lt;- airquality %&gt;% drop_na(Ozone) %&gt;% drop_na(Solar.R)\nvis_dat(cleaned_airdata)\n\n\n\n\n\n\n\nsummary(cleaned_airdata)\n\n     Ozone          Solar.R           Wind            Temp      \n Min.   :  1.0   Min.   :  7.0   Min.   : 2.30   Min.   :57.00  \n 1st Qu.: 18.0   1st Qu.:113.5   1st Qu.: 7.40   1st Qu.:71.00  \n Median : 31.0   Median :207.0   Median : 9.70   Median :79.00  \n Mean   : 42.1   Mean   :184.8   Mean   : 9.94   Mean   :77.79  \n 3rd Qu.: 62.0   3rd Qu.:255.5   3rd Qu.:11.50   3rd Qu.:84.50  \n Max.   :168.0   Max.   :334.0   Max.   :20.70   Max.   :97.00  \n     Month            Day       \n Min.   :5.000   Min.   : 1.00  \n 1st Qu.:6.000   1st Qu.: 9.00  \n Median :7.000   Median :16.00  \n Mean   :7.216   Mean   :15.95  \n 3rd Qu.:9.000   3rd Qu.:22.50  \n Max.   :9.000   Max.   :31.00  \n\n\n\n\nThe data is cleaned up now and I am choosing to use temperature as the predictor variable. I chose temperature because the ozone and temperature have a strong interaction as ozone formation is highly affected by temperature showing a positive correlation between the two.\n\nmodel &lt;- lm(Ozone ~ Temp, data = cleaned_airdata)\nsummary(model)\n\n\nCall:\nlm(formula = Ozone ~ Temp, data = cleaned_airdata)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-40.922 -17.459  -0.874  10.444 118.078 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -147.6461    18.7553  -7.872 2.76e-12 ***\nTemp           2.4391     0.2393  10.192  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 23.92 on 109 degrees of freedom\nMultiple R-squared:  0.488, Adjusted R-squared:  0.4833 \nF-statistic: 103.9 on 1 and 109 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nI think this is a valid model since there was a meaningful R-squared value, significant p-value results and a reasonable residual behavior.\n\n\nThe R^2 means that about 48.8% of the variablility in Ozone levels is explained by the predictor of temperature.\n\na_data &lt;- broom::augment(model, cleaned_airdata)\nhead(a_data)\n\n# A tibble: 6 × 12\n  Ozone Solar.R  Wind  Temp Month   Day .fitted .resid   .hat .sigma  .cooksd\n  &lt;int&gt;   &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt;\n1    41     190   7.4    67     5     1   15.8   25.2  0.0207   23.9 0.0120  \n2    36     118   8      72     5     2   28.0    8.03 0.0124   24.0 0.000714\n3    12     149  12.6    74     5     3   32.8  -20.8  0.0104   23.9 0.00405 \n4    18     313  11.5    62     5     4    3.58  14.4  0.0340   24.0 0.00662 \n5    23     299   8.6    65     5     7   10.9   12.1  0.0254   24.0 0.00342 \n6    19      99  13.8    59     5     8   -3.74  22.7  0.0444   23.9 0.0219  \n# ℹ 1 more variable: .std.resid &lt;dbl&gt;\n\n\n\nggplot(a_data, aes(x = .fitted, y = Ozone)) +\n  geom_point() + \n  geom_abline(intercept = 0, slope = 1, color = \"red\") +\n  labs(title = \"Actual VS Predicted Ozone Levels\",\n       subtitle = paste(\"Correlation:\", round(cor(a_data$Ozone,\n                                                  a_data$.fitted),2)),\n       x = \"Predicted Ozone Levels\",\n       y = \"Actual Ozone Levels\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nThe graph shows the linear relationship between the predicted and actual Ozone levels specifically showing a high correlation at 0.7."
  },
  {
    "objectID": "day-11-12.html",
    "href": "day-11-12.html",
    "title": "day-11-12",
    "section": "",
    "text": "data(\"airquality\")\nstr(airquality)\n\n'data.frame':   153 obs. of  6 variables:\n $ Ozone  : int  41 36 12 18 NA 28 23 19 8 NA ...\n $ Solar.R: int  190 118 149 313 NA NA 299 99 19 194 ...\n $ Wind   : num  7.4 8 12.6 11.5 14.3 14.9 8.6 13.8 20.1 8.6 ...\n $ Temp   : int  67 72 74 62 56 66 65 59 61 69 ...\n $ Month  : int  5 5 5 5 5 5 5 5 5 5 ...\n $ Day    : int  1 2 3 4 5 6 7 8 9 10 ...\n\nsummary(airquality)\n\n     Ozone           Solar.R           Wind             Temp      \n Min.   :  1.00   Min.   :  7.0   Min.   : 1.700   Min.   :56.00  \n 1st Qu.: 18.00   1st Qu.:115.8   1st Qu.: 7.400   1st Qu.:72.00  \n Median : 31.50   Median :205.0   Median : 9.700   Median :79.00  \n Mean   : 42.13   Mean   :185.9   Mean   : 9.958   Mean   :77.88  \n 3rd Qu.: 63.25   3rd Qu.:258.8   3rd Qu.:11.500   3rd Qu.:85.00  \n Max.   :168.00   Max.   :334.0   Max.   :20.700   Max.   :97.00  \n NA's   :37       NA's   :7                                       \n     Month            Day      \n Min.   :5.000   Min.   : 1.0  \n 1st Qu.:6.000   1st Qu.: 8.0  \n Median :7.000   Median :16.0  \n Mean   :6.993   Mean   :15.8  \n 3rd Qu.:8.000   3rd Qu.:23.0  \n Max.   :9.000   Max.   :31.0  \n                               \n\n\n\n\n\nshapiro.test(airquality$Ozone)\n\n\n    Shapiro-Wilk normality test\n\ndata:  airquality$Ozone\nW = 0.87867, p-value = 2.79e-08\n\nshapiro.test(airquality$Solar.R)\n\n\n    Shapiro-Wilk normality test\n\ndata:  airquality$Solar.R\nW = 0.94183, p-value = 9.492e-06\n\nshapiro.test(airquality$Wind)\n\n\n    Shapiro-Wilk normality test\n\ndata:  airquality$Wind\nW = 0.98575, p-value = 0.1178\n\nshapiro.test(airquality$Temp)\n\n\n    Shapiro-Wilk normality test\n\ndata:  airquality$Temp\nW = 0.97617, p-value = 0.009319"
  },
  {
    "objectID": "day-11-12.html#this-data-set-represents-air-quality-and-the-variables-that-affect-it-including-ozone-solar-radiation-wind-temperature.",
    "href": "day-11-12.html#this-data-set-represents-air-quality-and-the-variables-that-affect-it-including-ozone-solar-radiation-wind-temperature.",
    "title": "day-11-12",
    "section": "",
    "text": "shapiro.test(airquality$Ozone)\n\n\n    Shapiro-Wilk normality test\n\ndata:  airquality$Ozone\nW = 0.87867, p-value = 2.79e-08\n\nshapiro.test(airquality$Solar.R)\n\n\n    Shapiro-Wilk normality test\n\ndata:  airquality$Solar.R\nW = 0.94183, p-value = 9.492e-06\n\nshapiro.test(airquality$Wind)\n\n\n    Shapiro-Wilk normality test\n\ndata:  airquality$Wind\nW = 0.98575, p-value = 0.1178\n\nshapiro.test(airquality$Temp)\n\n\n    Shapiro-Wilk normality test\n\ndata:  airquality$Temp\nW = 0.97617, p-value = 0.009319"
  },
  {
    "objectID": "day-11-12.html#there-61-observations-for-the-season-of-fall-and-92-observations-from-the-summer-season.",
    "href": "day-11-12.html#there-61-observations-for-the-season-of-fall-and-92-observations-from-the-summer-season.",
    "title": "day-11-12",
    "section": "There 61 observations for the season of Fall and 92 observations from the Summer season.",
    "text": "There 61 observations for the season of Fall and 92 observations from the Summer season."
  },
  {
    "objectID": "day-11-12.html#why-is-it-necessary-to-both-prep-and-bake-the-recipe",
    "href": "day-11-12.html#why-is-it-necessary-to-both-prep-and-bake-the-recipe",
    "title": "day-11-12",
    "section": "Why is it necessary to both prep() and bake() the recipe?",
    "text": "Why is it necessary to both prep() and bake() the recipe?\n\nThe prep function is necessary to ensure that the preprocessing steps are based on the data so the transformations are fitted correctly. The bake function makes sure the transformations are applied consistently to all the data."
  },
  {
    "objectID": "day-11-12.html#the-r-squared-value-explains-about-62.5-of-the-variation-in-ozone-levels.-the-p-value-shows-the-model-is-statistically-significant.-in-terms-of-the-coefficients-temperature-and-wind-have-the-strongest-effects-while-day-of-the-month-is-not-a-significant-factor.",
    "href": "day-11-12.html#the-r-squared-value-explains-about-62.5-of-the-variation-in-ozone-levels.-the-p-value-shows-the-model-is-statistically-significant.-in-terms-of-the-coefficients-temperature-and-wind-have-the-strongest-effects-while-day-of-the-month-is-not-a-significant-factor.",
    "title": "day-11-12",
    "section": "The R-squared value explains about 62.5% of the variation in Ozone levels. The p-value shows the model is statistically significant. In terms of the coefficients, Temperature and wind have the strongest effects while day of the month is not a significant factor.",
    "text": "The R-squared value explains about 62.5% of the variation in Ozone levels. The p-value shows the model is statistically significant. In terms of the coefficients, Temperature and wind have the strongest effects while day of the month is not a significant factor."
  },
  {
    "objectID": "day-11-12.html#i-think-this-is-a-strong-enough-model-because-the-r-squared-accounted-for-about-62.5-of-the-variation-in-ozone-levels-and-the-p-value-was-statistically-significant.",
    "href": "day-11-12.html#i-think-this-is-a-strong-enough-model-because-the-r-squared-accounted-for-about-62.5-of-the-variation-in-ozone-levels-and-the-p-value-was-statistically-significant.",
    "title": "day-11-12",
    "section": "I think this is a strong enough model because the R-squared accounted for about 62.5% of the variation in ozone levels and the p-value was statistically significant.",
    "text": "I think this is a strong enough model because the R-squared accounted for about 62.5% of the variation in ozone levels and the p-value was statistically significant."
  },
  {
    "objectID": "draft_for_final.html",
    "href": "draft_for_final.html",
    "title": "Sea Level Rise Over Time (2010-2024)",
    "section": "",
    "text": "# Sea Level Rise in Virginia Key\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.4     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(lubridate)\n\nslr_data &lt;- read_csv(\"8723214_SLR_VirginiaKey.csv\", skip = 4, \n                     col_names = c(\"Year\", \"Month\", \"Monthly_MSL\", \"Linear_Trend\", \"High_Conf\", \"Low_Conf\"))\n\nWarning: One or more parsing issues, call `problems()` on your data frame for details,\ne.g.:\n  dat &lt;- vroom(...)\n  problems(dat)\n\n\nRows: 1064 Columns: 6\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (6): Year, Month, Monthly_MSL, Linear_Trend, High_Conf, Low_Conf\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nslr_data &lt;- slr_data %&gt;%\n  filter(!is.na(Year)) %&gt;%\n  mutate(\n    Monthly_MSL = as.numeric(Monthly_MSL),  # convert to numeric!\n    date = make_date(Year, Month, 1)\n  ) %&gt;%\n  filter(date &gt;= as.Date(\"2010-01-01\") & date &lt;= as.Date(\"2024-12-31\"))\n\nWarning: There were 3 warnings in `mutate()`.\nThe first warning was:\nℹ In argument: `Monthly_MSL = as.numeric(Monthly_MSL)`.\nCaused by warning:\n! NAs introduced by coercion\nℹ Run `dplyr::last_dplyr_warnings()` to see the 2 remaining warnings.\n\nggplot(slr_data, aes(x = date, y = Monthly_MSL)) +\n  geom_line(color = \"#1F77B4\", alpha = 0.5) +\n  geom_smooth(method = \"lm\", color = \"#D62728\", se = FALSE, size = 1.2) +\n  scale_y_continuous(\n    limits = c(0, 0.30),\n    breaks = seq(0, 0.30, by = 0.05),\n    labels = scales::number_format(accuracy = 0.01)\n  ) +\n  labs(\n    title = \"Sea Level Trend at Virginia Key (2010–2024)\",\n    x = \"Date\",\n    y = \"Monthly Mean Sea Level (meters)\"\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.y = element_text(size = 8)\n  )\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n`geom_smooth()` using formula = 'y ~ x'\n\n\nWarning: Removed 6 rows containing non-finite outside the scale range\n(`stat_smooth()`).\n\n\n\n\n\n\n\n\n\n\nSalinity Graph\n\n# Load necessary libraries\nlibrary(tidyverse)\nlibrary(lubridate)\n\n# Read the CSV file\nsalinity_data &lt;- read_csv(\"salinity.csv\")\n\nRows: 861 Columns: 181\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr   (49): Org_Identifier, Org_FormalName, Project_Identifier, Location_Ide...\ndbl    (7): Location_Latitude, Location_Longitude, Location_LatitudeStandard...\nlgl  (120): Project_Name, Project_QAPPApproved, Project_QAPPApprovalAgency, ...\ndate   (3): Activity_StartDate, Activity_EndDate, LastChangeDate\ntime   (2): Activity_StartTime, Activity_EndTime\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Convert and filter\nsalinity_data &lt;- salinity_data %&gt;%\n  mutate(Activity_StartDate = as.Date(Activity_StartDate)) %&gt;%\n  filter(Activity_StartDate &gt;= as.Date(\"2010-01-01\") & Activity_StartDate &lt;= as.Date(\"2024-12-31\"),\n         Location_CountyName == \"Miami-Dade County\")\n\n# Plot salinity over time for Miami-Dade County\nggplot(salinity_data, aes(x = Activity_StartDate, y = Result_Measure)) +\n  geom_line(color = \"steelblue\", size = 0.5) +\n  labs(title = \"Salinity in Miami-Dade County (ppth, 2010–2024)\",\n       x = \"Date\",\n       y = \"Salinity (ppth)\") +\n  theme_minimal()"
  },
  {
    "objectID": "day-21.html#decompose",
    "href": "day-21.html#decompose",
    "title": "Daily Assignment 21",
    "section": "Decompose:",
    "text": "Decompose:\n\nlibrary(fable)\nlibrary(feasts)\nlibrary(fabletools)\n\n# STL decomposition with a chosen seasonal window\npoudre_decomp &lt;- poudre_flow_tsibble %&gt;%\n  model(\n    stl = STL(Flow ~ season(window = \"periodic\"))\n  )\n\n# Plot the decomposed components\ncomponents(poudre_decomp) %&gt;%\n  autoplot() +\n  labs(title = \"STL Decomposition of Streamflow Data\") +\n  theme_minimal() +\n  theme(axis.text.y = element_text(size = 12))\n\n\n\n\n\n\n\n\n\nDescribe what you see in the plot. How do the components change over time? What do you think the trend and seasonal components represent?\n\nThe STL decompostion plot shows the streamflow data broken down into 3 components: trend, season of the year, and residuals (remainders). The trend component changes gradually over time, showing periods of increasing and decreasing flow, which may reflect long-term climate variation or watershed changes. The seasonal component is consistent across years, with distinct peaks May and June and lower flows in winter. The remainder flucatuates over time unpredictably, highlighting short-term variations like storms and droughts."
  }
]